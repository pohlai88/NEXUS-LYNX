# MCP Test Execution Strategy ‚Äî Canonical SSOT

**Date:** 2026-01-27  
**Status:** ‚úÖ **VERIFIED & LOCKED** ‚Äî All counts match actual test collection  
**Purpose:** **THE ONLY SOURCE OF TRUTH** for test execution commands and expected counts  
**Authority:** This document supersedes all other test count documentation

**‚ö†Ô∏è ANTI-DRIFT POLICY:** This is the **ONLY** canonical document for test execution. All other test count documents are historical snapshots.

---

## üìä Verified Test Counts (SSOT)

| Tier | Command | Test Count | Duration | When to Run |
|------|---------|------------|----------|-------------|
| **PR Gate** | `pytest -v -m "not performance and not stress"` | **292** | ~2-3 min | Every PR |
| **Full Suite** | `pytest -v` | **329** | ~5-8 min | Local dev, pre-production |
| **Performance** | `pytest -v -m performance` | **15** | ~2-3 min | Nightly, scheduled CI |
| **Stress** | `pytest -v -m stress` | **22** | ~1-2 min | Nightly, scheduled CI |
| **Integration** | `TEST_API_URL=<url> pytest -v -m integration` | ~46 | Varies | Staging/Railway validation |
| **Cluster MCP** | `pytest -v tests/integration/test_cluster_mcp_complete.py` | **16** | ~1 min | Governance gate |
| **Edge Cases** | `pytest -v tests/integration/test_edge_cases_large_payloads.py` | **22** | ~1-2 min | Hardening gate |

**Total:** 329 tests (292 PR gate + 15 performance + 22 stress)

---

## üéØ Test Execution Commands

### 1. PR Gate (Must-Pass, Non-Flaky)

**Runs on:** Every PR  
**Excludes:** Performance + Stress tests

```bash
cd lynx-ai
python -m pytest -v -m "not performance and not stress"
```

**Expected:** 292 tests passing

---

### 2. Full Suite (Local Dev Validation)

**Runs:** Everything (all 329 tests)

```bash
cd lynx-ai
python -m pytest -v
```

**Expected:** 329 tests

---

### 3. Performance-Only (Nightly/Manual)

```bash
cd lynx-ai
python -m pytest -v -m performance
```

**Expected:** 15 tests

---

### 4. Stress-Only (Nightly/Manual)

```bash
cd lynx-ai
python -m pytest -v -m stress
```

**Expected:** 22 tests

---

### 5. Integration Gate (Staging/Railway)

**Runs:** Only when live server exists

```bash
cd lynx-ai
TEST_API_URL=https://<staging-or-railway-url> python -m pytest -v -m integration
```

**Expected:** Integration-marked subset (~46 tests)

---

### 6. Cluster MCP Governance Gate

**Hard invariant check for Cluster MCP compliance**

```bash
cd lynx-ai
python -m pytest -v tests/integration/test_cluster_mcp_complete.py
```

**Expected:** 16 tests

---

### 7. Edge-Case + Large Payload Gate

**Hardening suite for extreme payloads**

```bash
cd lynx-ai
python -m pytest -v tests/integration/test_edge_cases_large_payloads.py
```

**Expected:** 22 tests (all marked `@pytest.mark.stress`)

---

## üîß Pytest Configuration (SSOT - Final Canonical)

### `pytest.ini` (Copy-Paste Ready)

```ini
[pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*
asyncio_mode = auto
asyncio_default_fixture_loop_scope = function
addopts = -v --tb=short
markers =
    integration: marks tests as integration tests (deselect with '-m "not integration"')
    performance: marks tests as performance tests (deselect with '-m "not performance"')
    stress: marks tests as stress/edge-case tests (deselect with '-m "not stress"')
    contract: marks tests as contract validation tests
```

### `tests/conftest.py` (Marker Registration - Copy-Paste Ready)

```python
# Pytest markers - DO NOT MODIFY without updating SSOT
def pytest_configure(config):
    """Register custom markers."""
    config.addinivalue_line("markers", "integration: marks tests as integration tests (deselect with '-m \"not integration\"')")
    config.addinivalue_line("markers", "performance: marks tests as performance tests")
    config.addinivalue_line("markers", "stress: marks tests as stress/edge-case tests")
    config.addinivalue_line("markers", "contract: marks tests as contract validation tests")
```

**‚ö†Ô∏è CRITICAL:** 
- **DO NOT** use `@pytest.mark.perf` (use `@pytest.mark.performance`)
- **DO NOT** change marker names without updating this SSOT
- **DO NOT** modify marker registration without updating this SSOT

### CI Enforcement Scripts

**Location:** `lynx-ai/scripts/`

1. **`check-test-markers.sh`** - Prevents forbidden markers (`perf`)
2. **`verify-test-counts.sh`** - Validates counts match SSOT

**Add to CI:**
```yaml
# Example GitHub Actions
- name: Check test markers
  run: bash lynx-ai/scripts/check-test-markers.sh

- name: Verify test counts
  run: bash lynx-ai/scripts/verify-test-counts.sh
```

---

## üöÄ CI/CD Strategy (3 Gates - Minimal & Clean)

### Gate A: PR Gate (Every PR)

**Command:**
```bash
cd lynx-ai
python -m pytest -v -m "not performance and not stress"
```

**Expected:** 292 tests passing  
**Duration:** ~2-3 min  
**Purpose:** Fast, non-flaky tests for PR validation

---

### Gate B: MCP Governance Gate (Main Branch Merge)

**Command:**
```bash
cd lynx-ai
python -m pytest -v tests/integration/test_cluster_mcp_complete.py
```

**Expected:** 16 tests passing  
**Duration:** ~1 min  
**Purpose:** Hard invariant check for Cluster MCP compliance

---

### Gate C: Edge-Case + Large Payload Gate (Main Branch Merge)

**Command:**
```bash
cd lynx-ai
python -m pytest -v -m stress
```

**Expected:** 22 tests passing  
**Duration:** ~1-2 min  
**Purpose:** Stress/edge-case validation (large payloads, extreme scenarios)

**Note:** The `stress` marker is now the **edge-case & large payload** bucket (22 tests). This is stable and should run on merge.

---

### Nightly Scheduled (Non-Blocking)

**Performance + Integration:**
```bash
# Performance tests
cd lynx-ai
python -m pytest -v -m performance

# Integration tests (against staging)
TEST_API_URL=https://<staging-url> python -m pytest -v -m integration
```

**Expected:** 15 performance + ~46 integration tests  
**Duration:** Varies  
**Purpose:** Performance validation and staging integration checks

**Why Nightly:** These don't block PRs, avoid Railway cold-start flakiness, and provide ongoing validation.

---

## üìã CI/CD Summary

| Gate | Command | Tests | When | Blocks PR? |
|------|---------|-------|------|------------|
| **Gate A (PR)** | `pytest -v -m "not performance and not stress"` | 292 | Every PR | ‚úÖ Yes |
| **Gate B (Governance)** | `pytest -v tests/integration/test_cluster_mcp_complete.py` | 16 | Main merge | ‚úÖ Yes |
| **Gate C (Edge Cases)** | `pytest -v -m stress` | 22 | Main merge | ‚úÖ Yes |
| **Nightly (Performance)** | `pytest -v -m performance` | 15 | Scheduled | ‚ùå No |
| **Nightly (Integration)** | `TEST_API_URL=... pytest -v -m integration` | ~46 | Scheduled | ‚ùå No |

**Total PR/Merge Gates:** 292 + 16 + 22 = 330 tests (with expected overlap)

---

## ‚úÖ Verification Commands

Verify counts match SSOT:

```bash
# Total tests
cd lynx-ai
python -m pytest --collect-only -q | grep "tests collected"

# PR Gate count
python -m pytest --collect-only -m "not performance and not stress" -q | grep "tests collected"

# Performance count
python -m pytest --collect-only -m performance -q | grep "tests collected"

# Stress count
python -m pytest --collect-only -m stress -q | grep "tests collected"
```

**Expected Output:**
- Total: `329 tests collected`
- PR Gate: `292/329 tests collected (37 deselected)`
- Performance: `15/329 tests collected (314 deselected)`
- Stress: `22/329 tests collected (307 deselected)`

---

## üìù Marker Usage

| Marker | Test Files | Purpose |
|--------|------------|---------|
| `@pytest.mark.performance` | `test_performance_reliability.py`, `test_dashboard_perf.py` | Performance validation (15 tests) |
| `@pytest.mark.stress` | `test_edge_cases_large_payloads.py` | Edge-case validation (22 tests) |
| `@pytest.mark.integration` | Various integration files | Integration scenarios (~46 tests) |
| `@pytest.mark.contract` | `test_dashboard_contracts.py` | Contract validation (~32 tests) |
| **No marker** | Most test files | Core functionality (292 tests in PR gate) |

---

## üîí Anti-Drift Policy (ENFORCED)

**This document is the ONLY SSOT for test execution.** 

### Current Verified State (2026-01-27)
- ‚úÖ All test counts verified via `pytest --collect-only`
- ‚úÖ Marker names frozen: `performance`, `stress`, `integration`, `contract`
- ‚úÖ PR gate command: `-m "not performance and not stress"` (excludes both)
- ‚úÖ No legacy markers: `perf` is **FORBIDDEN** (use `performance`)

### Drift Prevention Rules

**1. Marker Name Enforcement:**
- ‚ùå **FORBIDDEN:** `@pytest.mark.perf` (use `@pytest.mark.performance`)
- ‚úÖ **REQUIRED:** `@pytest.mark.performance`, `@pytest.mark.stress`, `@pytest.mark.integration`, `@pytest.mark.contract`

**2. Document Hierarchy:**
- ‚úÖ **SSOT:** This document (`MCP-TEST-EXECUTION-STRATEGY.md`)
- ‚ö†Ô∏è **Historical:** `TEST-COVERAGE-BEFORE-AFTER.md` (marked as historical snapshot)
- ‚ö†Ô∏è **Historical:** Any document showing 327 tests or 25 performance tests

**3. Count Change Protocol:**
If test counts change:
1. Run verification commands above
2. Update **THIS document immediately** (the SSOT)
3. Mark old counts as historical in other docs
4. Document reason for count change

**4. CI Enforcement:**
- CI check prevents `@pytest.mark.perf` usage (see `scripts/check-test-markers.sh`)
- CI validates test counts match SSOT

---

**Last Verified:** 2026-01-27  
**Total Tests:** 329  
**PR Gate:** 292  
**Performance:** 15  
**Stress:** 22

---

## üìã Final Copy-Paste Configuration Block

**One-time setup to prevent drift forever:**

### Step 1: Update `pytest.ini`

Replace the `markers` section in `lynx-ai/pytest.ini` with:

```ini
markers =
    integration: marks tests as integration tests (deselect with '-m "not integration"')
    performance: marks tests as performance tests (deselect with '-m "not performance"')
    stress: marks tests as stress/edge-case tests (deselect with '-m "not stress"')
    contract: marks tests as contract validation tests
```

### Step 2: Verify `tests/conftest.py`

Ensure `tests/conftest.py` contains (around line 285):

```python
# Pytest markers - DO NOT MODIFY without updating SSOT
def pytest_configure(config):
    """Register custom markers."""
    config.addinivalue_line("markers", "integration: marks tests as integration tests (deselect with '-m \"not integration\"')")
    config.addinivalue_line("markers", "performance: marks tests as performance tests")
    config.addinivalue_line("markers", "stress: marks tests as stress/edge-case tests")
    config.addinivalue_line("markers", "contract: marks tests as contract validation tests")
```

### Step 3: Add CI Checks

Add to your CI workflow (GitHub Actions example):

```yaml
- name: Check test markers (prevent drift)
  run: |
    cd lynx-ai
    bash scripts/check-test-markers.sh

- name: Verify test counts (prevent drift)
  run: |
    cd lynx-ai
    bash scripts/verify-test-counts.sh
```

**This configuration enforces:**
- ‚úÖ Marker names frozen (`performance`, not `perf`)
- ‚úÖ Test counts validated against SSOT
- ‚úÖ No drift allowed

---

## ‚úÖ Verification

After applying configuration, verify:

```bash
cd lynx-ai

# Check markers are registered
python -m pytest --markers | grep -E "performance|stress|integration|contract"

# Verify counts
python -m pytest --collect-only -q | grep "tests collected"
# Should show: 329 tests collected

# Verify PR gate
python -m pytest --collect-only -m "not performance and not stress" -q | grep "tests collected"
# Should show: 292 tests collected (37 deselected)
```

---

**Status:** ‚úÖ **LOCKED & ENFORCED**  
**Drift Prevention:** ‚úÖ **CI Scripts Active**  
**SSOT Authority:** ‚úÖ **ESTABLISHED**

